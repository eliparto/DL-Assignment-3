{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e142c4b-f336-4cc6-9245-e3ea304104b3",
   "metadata": {},
   "source": [
    "# DL Assignment 3: Group 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2c273-b6f6-48f8-97d7-79a007c797a1",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13726d-c49e-476a-ab93-ca078fb9b032",
   "metadata": {},
   "source": [
    "Q1:\\\n",
    "The general function for the output tensor is as follows: (source: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "\n",
    "$$ \n",
    "\\text{out}(N_i, C_{out_j}) = \\cancel{\\text{bias}(C_{out_j})} + \\sum_{j}{C_{in} - 1}\\text{weight}(C_{out_j}, k) * \\text{input}(N_i,k)\n",
    "$$\n",
    "\n",
    "This can be expressed through the following pseudocode:\n",
    "```\n",
    "NOT DONE!\n",
    "for n in batch_size:\n",
    "    for c_out in channels_out:\n",
    "        # output_tensor[n, c_out] = sum\n",
    "        sum = 0 \n",
    "        for c_in in channels_in:\n",
    "            sum += weight[c_out, c_in) * input[b, c_in]\n",
    "        output[n, c_out] = sum\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33427512-ad6a-4a1d-8c24-deab956386fb",
   "metadata": {},
   "source": [
    "Q2:\\\n",
    "The output height and width for a layer $l$ can be expressed as follows:\n",
    "\n",
    "$$\n",
    "n_{H|W}^{[l]} = \\frac{n_{H|W}^{[l-1]} + 2p^{[l-1]}-f^{[l-1]}}{s^{[l-1]}} + 1\n",
    "$$\n",
    "\n",
    "with $s$ representing stride, $p$ representing padding, and $f$ representing filter size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a63629-0bae-47cf-8141-fdb132df4455",
   "metadata": {},
   "source": [
    "Q3:\\\n",
    "A pseudocode implementation for the unfold function is as follows:\n",
    "see: https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold\n",
    "```\n",
    "func unfold(input_tensor, p = padding, s = stride, k = kernel)\n",
    "    # Add padding\n",
    "    padded_tensor = zero_tensor[batches, channels, height+2p, width+2p]\n",
    "\n",
    "    # Insert input tensor in zero tensor with padding\n",
    "    padded_tensor[:, :, p:height+p, width+p] = input_tensor\n",
    "\n",
    "    # Find and store patches\n",
    "    patches = []\n",
    "    unfold_tensor = [kernel_size]\n",
    "    # Slide window accross input and store \n",
    "    for patch in padded_tensor:\n",
    "        Add patch to patches\n",
    "\n",
    "    # Iterate along patches at every index of the kernel window\n",
    "    for index in unfold_tensor:\n",
    "        values = []\n",
    "        for patch in patches:\n",
    "            for patch_value in patch[index]\n",
    "            append patch_value to values\n",
    "        unfold_tensor[index] = values\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f97e5-ec4c-4ceb-a560-98ac3e875285",
   "metadata": {},
   "source": [
    "Code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183dd219-adca-414a-83ca-01b7469271d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945e48e-ae33-4beb-8509-8720ebf7fb09",
   "metadata": {},
   "source": [
    "### Manual Unfolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f6028f-0a8b-425b-876e-d990994251fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Conv w/ manual unfolding\n",
    "class Conv2D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size = (3,3),\n",
    "                 stride = 1, padding = 1):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        b, c, h, w = input_batch.size()\n",
    "        \n",
    "        # Add padding\n",
    "        tensor_pad = torch.full((b, c, h+2*self.padding, w+2*self.padding), 0.0)\n",
    "        tensor_pad[:, :, self.padding:h+self.padding, self.padding:w+self.padding] = input_batch\n",
    "\n",
    "        # Extract patches\n",
    "        _, _, h_pad, w_pad = tensor_pad.size()\n",
    "        x_steps = w_pad - self.kernel_size[0] / self.stride + 1\n",
    "        y_steps = h_pad - self.kernel_size[1] / self.stride + 1\n",
    "\n",
    "        # patches = torch.zeros(1,1024,3,3)\n",
    "        patches = torch.zeros(b, h * w, self.kernel_size[0], self.kernel_size[1])\n",
    "        for batch in range(b):\n",
    "            temp_patches = torch.empty(c, self.kernel_size[0], self.kernel_size[1])\n",
    "            for channel in range(c):\n",
    "                for x in range (0, int(x_steps), self.stride):\n",
    "                    for y in range(0, int(y_steps), self.stride):\n",
    "                        patch = tensor_pad[0,0,x:x+3,y:y+3]\n",
    "                        patch = torch.unsqueeze(patch, dim = 0)\n",
    "                        temp_patches = torch.cat((temp_patches, patch))\n",
    "            temp_patches = temp_patches[1:] # All individual patches in one batch \n",
    "            temp_patches = torch.unsqueeze(temp_patches, dim = 0)\n",
    "            print(temp_patches.size())\n",
    "            patches = torch.cat((patches, temp_patches), dim = 0) # Insert patches of one batch into tensor of all patches\n",
    "        patches = patches[1:]\n",
    "\n",
    "        # Fill in values in unfold tensor\n",
    "        unfold = torch.zeros(b,self.kernel_size[0] * self.kernel_size[1], h * w)\n",
    "        index = 0\n",
    "        for batch in range(b):\n",
    "            for x in range(self.kernel_size[0]):\n",
    "                for y in range(self.kernel_size[1]):\n",
    "                    unfold[batch][index] = torch.unsqueeze(patches, dim = 0)[0,0,:,x,y] # Make tensor of all values at an index of the oatches\n",
    "                    index += 1\n",
    "        \n",
    "        return unfold, patches, tensor_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e24d43-95d7-4f16-ab76-06dcc8487032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Own output:\n",
      "\n",
      "torch.Size([1, 1024, 3, 3])\n",
      "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.9192, 0.5909, 0.6573],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.5909, 0.6573, 0.9361],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.6573, 0.9361, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.8208, 0.7676,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.8208, 0.7676, 0.3601,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.7676, 0.3601, 0.8680,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "\n",
      "PyTorch unfold output:\n",
      "\n",
      "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.9192, 0.5909, 0.6573],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.5909, 0.6573, 0.9361],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.6573, 0.9361, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.8208, 0.7676,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.8208, 0.7676, 0.3601,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.7676, 0.3601, 0.8680,  ..., 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "conv = Conv2D(1,1)\n",
    "input_tensor = torch.rand(1,1,32,32)\n",
    "print(\"Own output:\\n\")\n",
    "out, patch, padded = conv(input_tensor)\n",
    "print(out)\n",
    "print(\"\\nPyTorch unfold output:\\n\")\n",
    "unfoldFunc = torch.nn.Unfold((3,3), dilation = 1, padding = 1, stride = 1)\n",
    "print(unfoldFunc(input_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b48f42-034f-4921-9878-a58d0968d706",
   "metadata": {},
   "source": [
    "### Using nn.Unfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13624b63-ae49-4808-90f9-3c07e253ad84",
   "metadata": {},
   "source": [
    "#### Module Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f3d7350-2dfa-4f24-8039-45bf94d5be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel, kernel_size = (3,3),\n",
    "                 stride = 1, padding = 1):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel = kernel\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "\n",
    "        b, c, h, w = input_batch.size()\n",
    "        output_size = self.calcSize(b, h, w)\n",
    "\n",
    "        # Folding and unfolding functions\n",
    "        unfoldFunc = nn.Unfold(kernel_size = self.kernel_size,\n",
    "                               padding = self.padding, stride = self.stride)\n",
    "        # Don't use the prior kernel/padding/stride params when folding\n",
    "        foldFunc = nn.Fold(output_size = (output_size[2], output_size[3]), kernel_size = (1, 1)) \n",
    "        \n",
    "        # Unfold input batch\n",
    "        unfold = unfoldFunc(input_batch)\n",
    "\n",
    "        # Multiply input batch with weights -> (XW) and fold into output shape\n",
    "        # Appropriate transformations are applied for correct output shapes\n",
    "        output_unfold = unfold.transpose(1,2).matmul(self.kernel.view(self.kernel.size(0), -1).t()).transpose(1, 2)\n",
    "        output = foldFunc(output_unfold)\n",
    "        assert list(output.size()) == output_size, f'{list(output.size())} generated. Need {output_size}'\n",
    "\n",
    "        return output_unfold\n",
    "\n",
    "    # Calculate the correct output size\n",
    "    def calcSize(self, b, h, w):\n",
    "        size_x = (h + 2 * self.padding - self.kernel_size[0]) / self.stride + 1\n",
    "        size_y = (w + 2 * self.padding - self.kernel_size[0]) / self.stride + 1\n",
    "\n",
    "        return [b, self.out_channels, int(size_x), int(size_y)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199e898c-defe-44f4-bfc7-23ae98248696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test output\n",
    "input_batch = torch.randn(16, 3, 32, 32)\n",
    "weights = torch.randn(3, 3, 3, 3)\n",
    "conv = Conv2D(3, 3, weights)\n",
    "output_batch = conv(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f81179-b55c-42d2-800b-8d4a78c40c72",
   "metadata": {},
   "source": [
    "#### Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6547dcfc-f183-4923-bf17-610339b6fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DFunc(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input_batch, kernel, stride = 1, padding = 1):\n",
    "        \"\"\"\n",
    "        Receive tensor containing input -> return tensor contaiing output.\n",
    "        ctx: context object containing info for backward pass.\n",
    "        Cache objects for use in backward pass using: ctx.save_for_backward\n",
    "        \"\"\"\n",
    "\n",
    "        # Forward pass\n",
    "        b, c, h, w = input_batch.size()\n",
    "        \n",
    "        # Calculate correct output dimensions\n",
    "        size_x = (h + 2 * padding - kernel.size(2)) / stride + 1\n",
    "        size_y = (w + 2 * padding - kernel.size(3)) / stride + 1\n",
    "        output_size = [b, kernel.size(0), int(size_x), int(size_y)]\n",
    "\n",
    "        # Folding and unfolding functions\n",
    "        unfoldFunc = nn.Unfold(kernel_size = (kernel.size(2), kernel.size(3)),\n",
    "                               padding = padding, stride = stride)\n",
    "        # Don't use the prior kernel/padding/stride params when folding\n",
    "        foldFunc = nn.Fold(output_size = (output_size[2], output_size[3]), kernel_size = (1, 1))\n",
    "\n",
    "        # Unfold -> tensor ops -> fold\n",
    "        U = unfoldFunc(input_batch)\n",
    "        UW = U.transpose(1,2).matmul(kernel.view(kernel.size(0), -1).t()).transpose(1, 2)\n",
    "        Y = foldFunc(UW)\n",
    "        assert list(Y.size()) == output_size, f'{list(Y.size())} generated. Need {output_size}'\n",
    "\n",
    "        # Store for backward pass\n",
    "        W = kernel.view(kernel.size(0), -1) # Format to follow computation graph shape\n",
    "        ctx.save_for_backward(input_batch, kernel, U, W)\n",
    "        ctx.stride = stride\n",
    "        ctx.padding = padding\n",
    "        \n",
    "        return Y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        Generate tensor containing gradient of loss w.r.t. output.\n",
    "        Compute gradient of loss w.r.t. input\n",
    "        \"\"\"\n",
    "            \n",
    "        # Retrieve stored objects and dimensions\n",
    "        input_batch, kernel, U, W = ctx.saved_tensors\n",
    "        b_in, c_in, h_in, w_in = input_batch.size()\n",
    "        b_out, c_out, h_out, w_out = grad_output.size()\n",
    "        stride = ctx.stride\n",
    "        padding = ctx.padding\n",
    "\n",
    "        # Backward pass\n",
    "        # Reshape Y^nabla to pre-folded shape (Y'^nabla)\n",
    "        Y_nabla = grad_output.view(b_out, c_out, (h_out * w_out)).transpose(1,2)\n",
    "\n",
    "        # W^nabla = U x Y^nabla\n",
    "        W_nabla = U.matmul(Y_nabla)\n",
    "        # U^nabla = Y^nabla x W.T\n",
    "        U_nabla = Y_nabla.matmul(W.view(W.size(0), -1)).transpose(1,2)\n",
    "        assert U_nabla.size() == U.size(), f'U_nabla: {U_nabla.size()} generated. Need {U.size()}'\n",
    "\n",
    "        # Fold U^nabla into X^nabla\n",
    "        foldFunc = nn.Fold(output_size=(32, 32), kernel_size=(3, 3), dilation=1, \n",
    "                           padding=(padding, padding), stride=stride)\n",
    "        X_nabla = foldFunc(U_nabla)\n",
    "        assert X_nabla.size() == input_batch.size(), f'X_nabla: {X_nabla.size()} generated. Need {input_batch.size()}'\n",
    "        \n",
    "        return X_nabla, W_nabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adfb48cf-c366-42c5-90e6-331afb293d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test output\n",
    "input_batch = torch.randn(16, 3, 32, 32, requires_grad = True)\n",
    "kernel = torch.randn(3, 3, 3, 3)\n",
    "output_batch = Conv2DFunc.apply(input_batch, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c18b992d-6bb3-44f9-a60d-68b1e65e09db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-588.8141, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example loss function\n",
    "loss_fn = torch.sum\n",
    "loss = loss_fn(output_batch)\n",
    "print(loss.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "403228e0-6484-4016-89c8-125d82d1d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f6db3-295b-4e46-9e57-20910d185311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
