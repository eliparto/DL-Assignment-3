{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e142c4b-f336-4cc6-9245-e3ea304104b3",
   "metadata": {},
   "source": [
    "# DL Assignment 3: Group 38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2c273-b6f6-48f8-97d7-79a007c797a1",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13726d-c49e-476a-ab93-ca078fb9b032",
   "metadata": {},
   "source": [
    "Q1:\\\n",
    "The general function for the output tensor is as follows: (source: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "\n",
    "$$ \n",
    "\\text{out}(N_i, C_{out_j}) = \\cancel{\\text{bias}(C_{out_j})} + \\sum_{j}{C_{in} - 1}\\text{weight}(C_{out_j}, k) * \\text{input}(N_i,k)\n",
    "$$\n",
    "\n",
    "This can be expressed through the following pseudocode:\n",
    "```\n",
    "NOT DONE!\n",
    "for n in batch_size:\n",
    "    for c_out in channels_out:\n",
    "        # output_tensor[n, c_out] = sum\n",
    "        sum = 0 \n",
    "        for c_in in channels_in:\n",
    "            sum += weight[c_out, c_in) * input[b, c_in]\n",
    "        output[n, c_out] = sum\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33427512-ad6a-4a1d-8c24-deab956386fb",
   "metadata": {},
   "source": [
    "Q2:\\\n",
    "The output height and width for a layer $l$ can be expressed as follows:\n",
    "\n",
    "$$\n",
    "n_{H|W}^{[l]} = \\frac{n_{H|W}^{[l-1]} + 2p^{[l-1]}-f^{[l-1]}}{s^{[l-1]}} + 1\n",
    "$$\n",
    "\n",
    "with $s$ representing stride, $p$ representing padding, and $f$ representing filter size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a63629-0bae-47cf-8141-fdb132df4455",
   "metadata": {},
   "source": [
    "Q3:\\\n",
    "A pseudocode implementation for the unfold function is as follows:\n",
    "see: https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold\n",
    "```\n",
    "func unfold(input_tensor, p = padding, s = stride, k = kernel)\n",
    "    # Add padding\n",
    "    padded_tensor = zero_tensor[batches, channels, height+2p, width+2p]\n",
    "\n",
    "    # Insert input tensor in zero tensor with padding\n",
    "    padded_tensor[:, :, p:height+p, width+p] = input_tensor\n",
    "\n",
    "    # Find and store patches\n",
    "    patches = []\n",
    "    unfold_tensor = [kernel_size]\n",
    "    # Slide window accross input and store \n",
    "    for patch in padded_tensor:\n",
    "        Add patch to patches\n",
    "\n",
    "    # Iterate along patches at every index of the kernel window\n",
    "    for index in unfold_tensor:\n",
    "        values = []\n",
    "        for patch in patches:\n",
    "            for patch_value in patch[index]\n",
    "            append patch_value to values\n",
    "        unfold_tensor[index] = values\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f97e5-ec4c-4ceb-a560-98ac3e875285",
   "metadata": {},
   "source": [
    "Code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183dd219-adca-414a-83ca-01b7469271d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945e48e-ae33-4beb-8509-8720ebf7fb09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Manual Unfolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f6028f-0a8b-425b-876e-d990994251fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Conv w/ manual unfolding\n",
    "class Conv2D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size = (3,3),\n",
    "                 stride = 1, padding = 1):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        b, c, h, w = input_batch.size()\n",
    "        \n",
    "        # Add padding\n",
    "        tensor_pad = torch.full((b, c, h+2*self.padding, w+2*self.padding), 0.0)\n",
    "        tensor_pad[:, :, self.padding:h+self.padding, self.padding:w+self.padding] = input_batch\n",
    "\n",
    "        # Extract patches\n",
    "        _, _, h_pad, w_pad = tensor_pad.size()\n",
    "        x_steps = w_pad - self.kernel_size[0] / self.stride + 1\n",
    "        y_steps = h_pad - self.kernel_size[1] / self.stride + 1\n",
    "\n",
    "        # patches = torch.zeros(1,1024,3,3)\n",
    "        patches = torch.zeros(b, h * w, self.kernel_size[0], self.kernel_size[1])\n",
    "        for batch in range(b):\n",
    "            temp_patches = torch.empty(c, self.kernel_size[0], self.kernel_size[1])\n",
    "            for channel in range(c):\n",
    "                for x in range (0, int(x_steps), self.stride):\n",
    "                    for y in range(0, int(y_steps), self.stride):\n",
    "                        patch = tensor_pad[0,0,x:x+3,y:y+3]\n",
    "                        patch = torch.unsqueeze(patch, dim = 0)\n",
    "                        temp_patches = torch.cat((temp_patches, patch))\n",
    "            temp_patches = temp_patches[1:] # All individual patches in one batch \n",
    "            temp_patches = torch.unsqueeze(temp_patches, dim = 0)\n",
    "            print(temp_patches.size())\n",
    "            patches = torch.cat((patches, temp_patches), dim = 0) # Insert patches of one batch into tensor of all patches\n",
    "        patches = patches[1:]\n",
    "\n",
    "        # Fill in values in unfold tensor\n",
    "        unfold = torch.zeros(b,self.kernel_size[0] * self.kernel_size[1], h * w)\n",
    "        index = 0\n",
    "        for batch in range(b):\n",
    "            for x in range(self.kernel_size[0]):\n",
    "                for y in range(self.kernel_size[1]):\n",
    "                    unfold[batch][index] = torch.unsqueeze(patches, dim = 0)[0,0,:,x,y] # Make tensor of all values at an index of the oatches\n",
    "                    index += 1\n",
    "        \n",
    "        return unfold, patches, tensor_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e24d43-95d7-4f16-ab76-06dcc8487032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Own output:\n",
      "\n",
      "torch.Size([1, 1024, 3, 3])\n",
      "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.7466, 0.3316, 0.1658],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.3316, 0.1658, 0.2210],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1658, 0.2210, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.4133, 0.4499,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4133, 0.4499, 0.8632,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4499, 0.8632, 0.5312,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "\n",
      "PyTorch unfold output:\n",
      "\n",
      "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.7466, 0.3316, 0.1658],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.3316, 0.1658, 0.2210],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1658, 0.2210, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.4133, 0.4499,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4133, 0.4499, 0.8632,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4499, 0.8632, 0.5312,  ..., 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "conv = Conv2D(1,1)\n",
    "input_tensor = torch.rand(1,1,32,32)\n",
    "print(\"Own output:\\n\")\n",
    "out, patch, padded = conv(input_tensor)\n",
    "print(out)\n",
    "print(\"\\nPyTorch unfold output:\\n\")\n",
    "unfoldFunc = torch.nn.Unfold((3,3), dilation = 1, padding = 1, stride = 1)\n",
    "print(unfoldFunc(input_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b48f42-034f-4921-9878-a58d0968d706",
   "metadata": {},
   "source": [
    "### Using nn.Unfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13624b63-ae49-4808-90f9-3c07e253ad84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Module Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f3d7350-2dfa-4f24-8039-45bf94d5be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel, kernel_size = (3,3),\n",
    "                 stride = 1, padding = 1):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel = kernel\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "\n",
    "        b, c, h, w = input_batch.size()\n",
    "        output_size = self.calcSize(b, h, w)\n",
    "\n",
    "        # Folding and unfolding functions\n",
    "        unfoldFunc = nn.Unfold(kernel_size = self.kernel_size,\n",
    "                               padding = self.padding, stride = self.stride)\n",
    "        # Don't use the prior kernel/padding/stride params when folding\n",
    "        foldFunc = nn.Fold(output_size = (output_size[2], output_size[3]), kernel_size = (1, 1)) \n",
    "        \n",
    "        # Unfold input batch\n",
    "        unfold = unfoldFunc(input_batch)\n",
    "\n",
    "        # Multiply input batch with weights -> (XW) and fold into output shape\n",
    "        # Appropriate transformations are applied for correct output shapes\n",
    "        output_unfold = unfold.transpose(1,2).matmul(self.kernel.view(self.kernel.size(0), -1).t()).transpose(1, 2)\n",
    "        print(output_unfold.size())\n",
    "        output = foldFunc(output_unfold)\n",
    "        assert list(output.size()) == output_size, f'{list(output.size())} generated. Need {output_size}'\n",
    "\n",
    "        return output_unfold\n",
    "\n",
    "    # Calculate the correct output size\n",
    "    def calcSize(self, b, h, w):\n",
    "        size_x = (h + 2 * self.padding - self.kernel_size[0]) / self.stride + 1\n",
    "        size_y = (w + 2 * self.padding - self.kernel_size[0]) / self.stride + 1\n",
    "\n",
    "        return [b, self.out_channels, int(size_x), int(size_y)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "199e898c-defe-44f4-bfc7-23ae98248696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 1024])\n"
     ]
    }
   ],
   "source": [
    "# Test output\n",
    "input_batch = torch.randn(16, 3, 32, 32)\n",
    "weights = torch.randn(3, 3, 3, 3)\n",
    "conv = Conv2D(3, 3, weights)\n",
    "output_batch = conv(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f81179-b55c-42d2-800b-8d4a78c40c72",
   "metadata": {},
   "source": [
    "#### Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6547dcfc-f183-4923-bf17-610339b6fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DFunc(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input_batch, kernel, stride = 1, padding = 1):\n",
    "        \"\"\"\n",
    "        Receive tensor containing input -> return tensor contaiing output.\n",
    "        ctx: context object containing info for backward pass.\n",
    "        Cache objects for use in backward pass using: ctx.save_for_backward\n",
    "        \"\"\"\n",
    "\n",
    "        # Store objects for backward pass\n",
    "        #ctx.save_for_backward(input_batch)\n",
    "        #ctx.save_for_backward(kernel)\n",
    "\n",
    "        # Forward pass\n",
    "        b, c, h, w = input_batch.size()\n",
    "        \n",
    "        # Calculate correct output dimensions\n",
    "        size_x = (h + 2 * padding - kernel.size(2)) / stride + 1\n",
    "        size_y = (w + 2 * padding - kernel.size(3)) / stride + 1\n",
    "        output_size = [b, kernel.size(0), int(size_x), int(size_y)]\n",
    "\n",
    "        # Folding and unfolding functions\n",
    "        unfoldFunc = nn.Unfold(kernel_size = (kernel.size(2), kernel.size(3)),\n",
    "                               padding = padding, stride = stride)\n",
    "        # Don't use the prior kernel/padding/stride params when folding\n",
    "        foldFunc = nn.Fold(output_size = (output_size[2], output_size[3]), kernel_size = (1, 1))\n",
    "\n",
    "        # Unfold -> tensor ops -> fold\n",
    "        U = unfoldFunc(input_batch)\n",
    "        UW = U.transpose(1,2).matmul(kernel.view(kernel.size(0), -1).t()).transpose(1, 2)\n",
    "        Y = foldFunc(UW)\n",
    "        assert list(Y.size()) == output_size, f'{list(Y.size())} generated. Need {output_size}'\n",
    "\n",
    "        # Store U and W for backward pass\n",
    "        W = kernel.view(kernel.size(0), -1)\n",
    "        #ctx.save_for_backward(W)\n",
    "        #ctx.save_for_backward(U)\n",
    "\n",
    "        ctx.save_for_backward(input_batch, kernel, U, W)\n",
    "        \n",
    "        return Y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        Generate tensor containing gradient of loss w.r.t. output.\n",
    "        Compute gradient of loss w.r.t. input\n",
    "        \"\"\"\n",
    "        \n",
    "        # grad_input = grad_output * 2\n",
    "\n",
    "        # Retrieve stored objects\n",
    "        input_batch, kernel, U, W = ctx.saved_tensors\n",
    "        \n",
    "        # return grad_input, grad_input\n",
    "        \n",
    "        b, c, h, w = grad_output.size()\n",
    "\n",
    "        # Backward pass\n",
    "        # Reshape Y^nabla to pre-folded shape (Y')\n",
    "        Y_nabla = grad_output.view(b, c, (h * w))\n",
    "\n",
    "        # W^nabla = U x Y^nabla\n",
    "        W_nabla = U.matmul(Y_nabla)\n",
    "        # U^nabla = Y^nabla x W.T\n",
    "        U_nabla = Y_nabla.matmul(W.view(W.size(0), -1))\n",
    "\n",
    "        # Reshape U into X and W back to normal form\n",
    "        print(W_nabla.size())\n",
    "        print(U_nabla.size())\n",
    "        \n",
    "        return U_nabla, W_nabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfb48cf-c366-42c5-90e6-331afb293d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test output\n",
    "input_batch = torch.randn(16, 3, 32, 32, requires_grad = True)\n",
    "kernel = torch.randn(3, 3, 3, 3)\n",
    "output_batch = Conv2DFunc.apply(input_batch, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18b992d-6bb3-44f9-a60d-68b1e65e09db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4020.0786, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example loss function\n",
    "loss_fn = torch.sum\n",
    "loss = loss_fn(output_batch)\n",
    "print(loss.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "403228e0-6484-4016-89c8-125d82d1d3e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [16, 1024] but got: [16, 3].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/mlai/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/mlai/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/mlai/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/mlai/lib/python3.11/site-packages/torch/autograd/function.py:307\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 65\u001b[0m, in \u001b[0;36mConv2DFunc.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     62\u001b[0m Y_nabla \u001b[38;5;241m=\u001b[39m grad_output\u001b[38;5;241m.\u001b[39mview(b, c, (h \u001b[38;5;241m*\u001b[39m w))\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# W^nabla = U x Y^nabla\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m W_nabla \u001b[38;5;241m=\u001b[39m \u001b[43mU\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_nabla\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# U^nabla = Y^nabla x W.T\u001b[39;00m\n\u001b[1;32m     67\u001b[0m U_nabla \u001b[38;5;241m=\u001b[39m Y_nabla\u001b[38;5;241m.\u001b[39mmatmul(W\u001b[38;5;241m.\u001b[39mview(W\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [16, 1024] but got: [16, 3]."
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffccbe1-d4d1-4ce5-98eb-4debdbaf3af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
